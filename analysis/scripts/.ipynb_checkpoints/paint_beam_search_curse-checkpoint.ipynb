{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed input directory is /Users/elliott/weixin/beam-search/beam-search-decoding/analysis/scripts/../archive/ende_dfstopk_wmt14.en-de.transformer_new_beam_100.\n",
      "Reading cached outputs from:\n",
      "/Users/elliott/weixin/beam-search/beam-search-decoding/analysis/scripts/../archive/ende_dfstopk_wmt14.en-de.transformer_new_beam_100.outs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3003 [00:00<01:48, 27.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dict length: 3003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3003/3003 [01:20<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.141080447903068\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sacrebleu\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import pickle\n",
    "import pdb\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    dfs_path = args['input_dir']\n",
    "    beam_size  = args['beam']\n",
    "    base_name = os.path.basename(dfs_path)\n",
    "    dir_name = os.path.dirname(dfs_path)\n",
    "    cached_path = os.path.join(dir_name, base_name + '.outs')\n",
    "    print(\"Computed input directory is {}.\".format(dfs_path))\n",
    "    \n",
    "    # read in references\n",
    "    ref_file = args['reference_file']\n",
    "    refs = read(ref_file)\n",
    "\n",
    "    if not os.path.exists(cached_path):\n",
    "        print('Extracting outputs!')\n",
    "        dfs_outputs = read_split_files(dfs_path, beam_size)\n",
    "\n",
    "        ### delbpe && detok for texts, evaluate bleu scores\n",
    "        funct = partial(call_delbpe_and_detok, script_path=args['script_path'])\n",
    "        dbpe_detok_dfstopk_outputs = process_text_in_moses_format(dfs_outputs, funct)\n",
    "        with open(cached_path, 'wb') as f:\n",
    "            pickle.dump(dbpe_detok_dfstopk_outputs, f)\n",
    "    else:\n",
    "        print(\"Reading cached outputs from:\")\n",
    "        print(\"{}\".format(cached_path))\n",
    "        with open(cached_path, 'rb') as f:\n",
    "            dbpe_detok_dfstopk_outputs = pickle.load(f)\n",
    "            \n",
    "    print('Output dict length: {}'.format(len(dbpe_detok_dfstopk_outputs)))\n",
    "    dfstopk_scores = score_all_outputs(dbpe_detok_dfstopk_outputs, refs)\n",
    "\n",
    "#     np.histogram(ed_result_cat, bins=10)\n",
    "    for i in range(len(dfstopk_scores[0])):\n",
    "        rank_scores = [item[i] for item in dfstopk_scores]\n",
    "        if i == 0:\n",
    "            result_cat = np.array(rank_scores).reshape(1, -1)\n",
    "        else:\n",
    "            result_cat = np.concatenate([result_cat, np.array(rank_scores).reshape(1, -1)], axis=0)\n",
    "    print(result_cat.mean())\n",
    "    return result_cat\n",
    "        \n",
    "\n",
    "root = \"/Users/elliott/weixin/beam-search/beam-search-decoding/analysis/scripts\"\n",
    "script_path=os.path.join(root, \"../model_errors\")\n",
    "ref_file=os.path.join(root, \"../model_errors/test.de.tok.detok\")\n",
    "input_dir = os.path.join(root, \"../archive/ende_dfstopk_wmt14.en-de.transformer_new_beam_100\")\n",
    "    \n",
    "args = {\n",
    "    'input_dir': input_dir,\n",
    "    'beam': 5,\n",
    "    'reference_file': ref_file,\n",
    "    'script_path': script_path\n",
    "}\n",
    "result_cat = main(args)\n",
    "# def parse_args(args=None):\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         usage=\"compute_model_errors.py [<args>] [-h | --help]\"\n",
    "#     )\n",
    "\n",
    "#     # in moses format\n",
    "#     parser.add_argument(\"--input_dir\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--beam\", type=int, default=5)\n",
    "#     parser.add_argument(\"--reference_file\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--script_path\", type=str, default=\"\")\n",
    "#     parser.add_argument(\"--disable_cache\", action='store_true')\n",
    "\n",
    "#     return parser.parse_args(args)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     args = parse_args()\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_histogram(result_cat):\n",
    "    hists = []\n",
    "    for i in range(0, 20):\n",
    "#         hists.append(np.histogram(result_cat[i*5:(i+1)*5], bins=10))\n",
    "\n",
    "hists = paint_histogram(result_cat)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(result_cat, density=True, bins=30)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')\n",
    "# plt.savefig(out_path)\n",
    "# plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
